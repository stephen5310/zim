Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2022-09-08T17:46:33+02:00

====== Section 17 ======
Created jeudi 08 septembre 2022

====== Decoupling applications ======

===== SQS =====

==== Default ====

* Queue model
* Fully managed to decouple apps
* What sends messages into the queue is called a Producer :
	* Use the SDK with SendMessage API
	* Message is persisted until a consumer deletes it
* The queue polls messages to Consumers which :
	* Apps running on EC2, servers, or Lambda
	* Process messages (insert into RDS)
	* Delete messages after with DeleteMessage API
	* Can be multiple
* Unlimited throughput, number of messages in queue
* Default retention : 4days default, max of 14d
* Low latency <10ms on publish and receive
* Limitation of 256kb / msg sent
* Can have duplicate messages (at least once delivery)
* Can have out of order messages (best effort ordering)
* Security with :
	* in-flight encryption using HTTPS API
	* At-rest encryption using KMS keys
	* Client-side encryption
	* IAM policies to regulate access to SQS API
	* SQS Access Policies (similar to S3 bucket policies) :
		* For cross-account access to SQS queues
		* For allowing other services to write to an SQS queue

==== Access Policy ====

* Can write custom ones or choose default ones
* Google to find the right way to grant permissions
* Cross Account Access to poll messages to another account EC2 instance
* Publish S3 event notifications to SQS queue

==== Message Visibility Timeout ====

* Time of invisibility of a message after it has been polled by a consumer
* Default is 30s, must be set to a reasonable value
* After that, if not deleted it will be available to every consumer
* Consumer can call ChangeMessageVisibility API to get more time

==== Dead Letter Queues ====

* Another SQS queue to create to help for debugging the source queue
* Just add it in the Dead-letter queue options of the source queue
* Can set a MaximumReceives threshold of how many times a message can go back to the source queue
* If threshold is reached, message goes to Dead Letter Queue (DLQ)
* Useful for debugging
* Make sure to process them before they expire (i.e. set to 14 days)
* Redrive to Source feature :
	* Helps conume messages in DLQ to understant what is wrong
	* After fixing the code, it redrives messages into the source queue in batches

==== Delay Queues ====

* Change the parameter Deliver delay in the conf
* Delay a message up to 15mn so consumers don't see it immediately
* Default is 0s
* Can set a default at queue level
* Can override the default on send using DelaySeconds parameter

==== Long Polling ====

* When there is no messages the consumer can wait for messages
* Decreases the number of API calls
* Can be btw 1s to 20s
* Can be enabled at queue level or using WaitTimeSeconds

==== Request-Response Systems ====

* Can use SQS Temporary Queue Client to create :
	* Leverages virtual queues instead of creating / deleting queues
* Use SQS as middleware between requesters and responders
* Requesters send messages to a queue with correlation ID, the content and queue to reply to
* Responders will :
	* Poll the messages
	* Process them
	* Create the reponse queue if does not exist
	* Send the response in this queue with the same corID
* Requesters will poll the response queue they sent in their request

==== FIFO Queues ====

* First in first out
* Name of the queue must end with .fifo
* Limited throughput : 300 msg/s without batching, 3000 msg/s with
* Exactily once send capability (by removing duplicates)
* Messages are processed in order by the consumer
* **Group ID are used to group data and have multiple consumers to read groups data in order**

==== SQS with ASG ====

* Write CloudWatch Custom Metric to monitor the Queue Length out of the Number of EC2 Instances
* A CloudWatch Alarm is raised when Queue Length goes above threshold
* Alarm linked to an ASG scaling policy to scale automatically

===== SNS =====

* pub/sub model
* Subscriptions are created within topic conf
* Send one message for many receivers
* Event producer sends messages to one SNS topic
* Every receivers can listen to topic notifications
* Each receiver will receive all the messages except when using a filter
* Up to 12,500,000 subscriptions per topic
* 100,000 topics limit
* Can send email, SMS & mobile notifs, HTTPS Endpoints
* Can connect to SQS, Lambda, Kinesis Data Firehose
* Receives data from CloudWatch Alarms, Lambda, ASG, S3 buckets, DynamoDB, RDS Events, ...
* To publish use the Topic Publish (SDK) :
	* Create Topic, subscriptions and Publish Topic
* Can use Direct Publish (for mobile apps SDK)
	* Create platform app, endpoint and Publish to platform endpoint
	* Works with Google GCM, Apple APNS, Amazon ADM, ...
* Security : same as SQS
* Has FIFO mode similar to SQS
* Can be connected to Kinesis Data Firehose for data persistence
* Message filtering with subscription Filter policy
	* Subscribers without Filter policy receive every messages

==== Add SQS for Fan Out ====

* Used to send on message to a scalable number of SQS queues
* Push once in SNS, receive in all subscribers SQS queues
* Fully decoupled, no data loss
* SQS allows for data persistence, delayed processing and retries of work
* Make sure your SQS queue access policy allows for SNS to write

===== Kinesis =====

* Real-time streaming model
* Makes it easy to collect, process and analyze streaming data in real-time
* Ingest real-time data such as : Apps logs, Metrics, Website clickstreams, IoT telemetry data...

==== Kinesis Data Streams ====

* capture, process and store data streams
* Real time with 200ms latency
* Streams are made of shards that can be scaled horizontally
* A shard can receive up to 1MB/sec of 1000msg/sec **????????**
* Producers send records into streams :
	* AWS SDK, Kinesis Producer Library (KPL), Kinesis Agent
* Record is made of a partition key and a data blob (1MB max)
* Same key will alvays go to the same shard :
	* **Data is ordered for the same source at the shard level**
	* **Data is read in order using the same key**
* Consumer receives record with a sequence number :
	* Write your own : Kinesis Client Library (KCL), AWS SDK
	* Managed : Lambda, KDF, KDA
* Pub/sub model
* Two subscription modes :
	* Shared : 2MB/s per shard for all consumers
	* Enhanced : 2MB/s per shard per consumer
* Retention btw 1d to 365d
* Ability to reprocess/replay data
* Once data is inserted, it can't be deleted (immutability)
* Data that shares the same partition goes to the same shard (ordering)
* Capacity modes :
	* Provisioned :
		* Choose number of shards, scale manually or using API
		* Each shard gets 1MB/s in and 2MB/s out
		* Pay per shard provisioned per hour
	* On-demand :
		* Default capacity is 4MB/s in and no limit out
		* Scales auto based on observed throughput peak during the last 30d
		* Pay per stream per hour & data in/out per GB

==== Kinesis Data Firehose ====

* Fully managed, auto-scaling, serverless
* Load data streams into AWS data stores
* Reads records from Producers
* Can transform data with Lambda functions
* Batch writes to destinations for Near Real Time service :
	* 60s min latency for non full batches
	* Min 32MB data at a time
* Destination can be : 
	* Any AWS or 3rd-party partner database or compatible storage
	* Any custom compatible HTTP Endpoint
* All or failed data can be sent to an S3 backup bucket
* Pay for data going through
* Supports many data formats, conversions, transformations, compression

==== Kinesis Data Analytics ====

* Analyze data streams with SQL statements or Apache Flink
* Sources are KDS and KDF
* Sinks are KDS and KDF
* Real time analytics
* Fully managed
* Used for :
	* Time-series analytics
	* RT dashboards
	* RT metrics
* Pay for actual consumption rate

==== Kinesis Video Streams ====

* Capture, process and store video streams

===== Amazon MQ =====

* Managed Apache ActiveMQ
* Used for migrating message queues from on premises
* Compatible with open standards used by MQTT, AMQP, STOMP, Openwire and WSS
* Does not scale as much as cloud native ones
* Runs on a dedicated machine, can run in HA with failover :
	* Must define EFS as backend storage
* Has both queue and pub/sub model
